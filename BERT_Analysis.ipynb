{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "49198e0a",
   "metadata": {},
   "source": [
    "### Text Analysis using BERT to classify MIBT Personality"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "863c4b11",
   "metadata": {},
   "source": [
    "##### Including imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33c96769",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import regex as re\n",
    "import string as st\n",
    "\n",
    "# visualization imports\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#splitting into 70 30\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#BERT\n",
    "import tensorflow as tf\n",
    "import transformers\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from transformers import BertTokenizer\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7a398d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"mbti_1.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d592d465",
   "metadata": {},
   "source": [
    "### Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "230771d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       'http://www.youtube.com/watch?v=qsXHcwe3krw|||...\n",
       "1       'I'm finding the lack of me in these posts ver...\n",
       "2       'Good one  _____   https://www.youtube.com/wat...\n",
       "3       'Dear INTP,   I enjoyed our conversation the o...\n",
       "4       'You're fired.|||That's another silly misconce...\n",
       "                              ...                        \n",
       "8670    'https://www.youtube.com/watch?v=t8edHB_h908||...\n",
       "8671    'So...if this thread already exists someplace ...\n",
       "8672    'So many questions when i do these things.  I ...\n",
       "8673    'I am very conflicted right now when it comes ...\n",
       "8674    'It has been too long since I have been on per...\n",
       "Name: posts, Length: 8675, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Cleaning data to remove url and symbols. The pipe is used to separate posts so will be replaced with spaces\n",
    "data.posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60abd4cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaningPosts(data):\n",
    "    cleanPosts = []\n",
    "    for post in data.posts:\n",
    "        post = post.lower()\n",
    "        post = re.sub('(https|http):\\/\\/[0-9a-zA-Z\\.\\-]+\\.[a-zA-Z]{1,5}(\\/\\S*)?', ' ', post)\n",
    "        post = re.sub('[^0-9a-zA-Z]', ' ', post)   \n",
    "        cleanPosts.append(post)\n",
    "    return cleanPosts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "62d1b062",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.posts = cleaningPosts(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6234f94",
   "metadata": {},
   "source": [
    "### Data Preview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a88f024f",
   "metadata": {},
   "source": [
    "### 16 Personality Types in this Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "08fab96c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>posts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>and intj moments     sportscenter not top t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENTP</td>\n",
       "      <td>i m finding the lack of me in these posts ver...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INTP</td>\n",
       "      <td>good one            course  to which i say i ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>INTJ</td>\n",
       "      <td>dear intp    i enjoyed our conversation the o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ENTJ</td>\n",
       "      <td>you re fired    that s another silly misconce...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8670</th>\n",
       "      <td>ISFP</td>\n",
       "      <td>just because i always think of cats as fi d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8671</th>\n",
       "      <td>ENFP</td>\n",
       "      <td>so   if this thread already exists someplace ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8672</th>\n",
       "      <td>INTP</td>\n",
       "      <td>so many questions when i do these things   i ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8673</th>\n",
       "      <td>INFP</td>\n",
       "      <td>i am very conflicted right now when it comes ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8674</th>\n",
       "      <td>INFP</td>\n",
       "      <td>it has been too long since i have been on per...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8675 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      type                                              posts\n",
       "0     INFJ     and intj moments     sportscenter not top t...\n",
       "1     ENTP   i m finding the lack of me in these posts ver...\n",
       "2     INTP   good one            course  to which i say i ...\n",
       "3     INTJ   dear intp    i enjoyed our conversation the o...\n",
       "4     ENTJ   you re fired    that s another silly misconce...\n",
       "...    ...                                                ...\n",
       "8670  ISFP     just because i always think of cats as fi d...\n",
       "8671  ENFP   so   if this thread already exists someplace ...\n",
       "8672  INTP   so many questions when i do these things   i ...\n",
       "8673  INFP   i am very conflicted right now when it comes ...\n",
       "8674  INFP   it has been too long since i have been on per...\n",
       "\n",
       "[8675 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee0030e3",
   "metadata": {},
   "source": [
    "### The number of posts classified based on the personality type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "814b9234",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "INFP    1832\n",
       "INFJ    1470\n",
       "INTP    1304\n",
       "INTJ    1091\n",
       "ENTP     685\n",
       "ENFP     675\n",
       "ISTP     337\n",
       "ISFP     271\n",
       "ENTJ     231\n",
       "ISTJ     205\n",
       "ENFJ     190\n",
       "ISFJ     166\n",
       "ESTP      89\n",
       "ESFP      48\n",
       "ESFJ      42\n",
       "ESTJ      39\n",
       "Name: type, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### The data is not as balanced therefore there might be some bias\n",
    "\n",
    "data['type'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1e2d9e6",
   "metadata": {},
   "source": [
    "### Preparation for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1a57dd90",
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting\n",
    "trainData, testData = train_test_split(data, random_state = 0, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b9bb98b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "### using Tokenizer\n",
    "\n",
    "def tokenizing(posts, tokenizer, maxLen = 150):\n",
    "    allTokens = []\n",
    "    for post in tqdm(posts):\n",
    "        token = tokenizer.encode(post, add_special_tokens=True, max_length = maxLen)\n",
    "        allTokens.append(token)\n",
    "    return allTokens\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6d565121",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(bertLayer, maxLen = 150):\n",
    "    input_word_ids = Input(shape=(maxLen,), dtype=tf.int32, name=\"input_word_ids\")\n",
    "    bertOutput = bertLayer(input_word_ids)[0]\n",
    "    output = Dense(16, activation='softmax')(bertLayer(input_word_ids)[0][:,0,:])\n",
    "    model = Model(inputs=input_word_ids, outputs=output)\n",
    "    model.compile(optimizer=Adam(learning_rate=0.000002), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eec00e16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a6f54ed5f674493b75b3e0690929062",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6072 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f29b8d0bf8a420cbf027ce0aa6aa7fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2603 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
    "trainInputs = tokenizing(trainData['posts'], tokenizer)\n",
    "trainInputs = pad_sequences(trainInputs, maxlen=150, dtype=\"long\", truncating='post', padding = 'post')\n",
    "testInputs = tokenizing(testData['posts'], tokenizer)\n",
    "testInputs = pad_sequences(testInputs, maxlen=150, dtype=\"long\", truncating='post', padding = 'post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "25e74a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "types = np.unique(data.type.values)\n",
    "\n",
    "def get_type_index(string):\n",
    "    return list(types).index(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "436c48f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>posts</th>\n",
       "      <th>type_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3162</th>\n",
       "      <td>INFP</td>\n",
       "      <td>nvm   are you good at helping other people  s...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>ENTP</td>\n",
       "      <td>well  sorry  but i just think this is another...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6248</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>lol      hahaha  first of all    stop address...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2843</th>\n",
       "      <td>ENTP</td>\n",
       "      <td>i thought personality cafe had a rate my pic ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5281</th>\n",
       "      <td>INFP</td>\n",
       "      <td>same problem here  i cant get onto my origina...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4373</th>\n",
       "      <td>INFP</td>\n",
       "      <td>hey  it seems like you have a great foundatio...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7891</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>dear istj mother    when i started my very fi...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4859</th>\n",
       "      <td>INTP</td>\n",
       "      <td>oh entjs  how can you be scary and exciting a...</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3264</th>\n",
       "      <td>ENFJ</td>\n",
       "      <td>hi  entp  and welcome to the forum  wink    f...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2732</th>\n",
       "      <td>ENTP</td>\n",
       "      <td>interesting  you ve gone from se dominant to n...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6072 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      type                                              posts  type_index\n",
       "3162  INFP   nvm   are you good at helping other people  s...           9\n",
       "320   ENTP   well  sorry  but i just think this is another...           3\n",
       "6248  INFJ   lol      hahaha  first of all    stop address...           8\n",
       "2843  ENTP   i thought personality cafe had a rate my pic ...           3\n",
       "5281  INFP   same problem here  i cant get onto my origina...           9\n",
       "...    ...                                                ...         ...\n",
       "4373  INFP   hey  it seems like you have a great foundatio...           9\n",
       "7891  INFJ   dear istj mother    when i started my very fi...           8\n",
       "4859  INTP   oh entjs  how can you be scary and exciting a...          11\n",
       "3264  ENFJ   hi  entp  and welcome to the forum  wink    f...           0\n",
       "2732  ENTP  interesting  you ve gone from se dominant to n...           3\n",
       "\n",
       "[6072 rows x 3 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainData['type_index'] = data['type'].apply(get_type_index)\n",
    "trainData"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afb570bb",
   "metadata": {},
   "source": [
    "### Building the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "29503186",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at bert-large-uncased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n",
      "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertModel were initialized from the model checkpoint at bert-large-uncased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "bertLayer= transformers.TFBertModel.from_pretrained('bert-large-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b9c3b06e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_word_ids (InputLayer)  [(None, 150)]            0         \n",
      "                                                                 \n",
      " tf_bert_model (TFBertModel)  TFBaseModelOutputWithPoo  335141888\n",
      "                             lingAndCrossAttentions(l            \n",
      "                             ast_hidden_state=(None,             \n",
      "                             150, 1024),                         \n",
      "                              pooler_output=(None, 10            \n",
      "                             24),                                \n",
      "                              past_key_values=None, h            \n",
      "                             idden_states=None, atten            \n",
      "                             tions=None, cross_attent            \n",
      "                             ions=None)                          \n",
      "                                                                 \n",
      " tf.__operators__.getitem (S  (None, 1024)             0         \n",
      " licingOpLambda)                                                 \n",
      "                                                                 \n",
      " dense (Dense)               (None, 16)                16400     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 335,158,288\n",
      "Trainable params: 335,158,288\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = create_model(bertLayer, maxLen = 150)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b77665be",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_labels = tf.keras.utils.to_categorical(trainData.type_index.values, num_classes=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5e87e67e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "3036/3036 [==============================] - ETA: 0s - loss: 2.3090 - accuracy: 0.2139WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "3036/3036 [==============================] - 607s 194ms/step - loss: 2.3090 - accuracy: 0.2139\n",
      "Epoch 2/20\n",
      "3036/3036 [==============================] - ETA: 0s - loss: 2.0331 - accuracy: 0.3340WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "3036/3036 [==============================] - 586s 193ms/step - loss: 2.0331 - accuracy: 0.3340\n",
      "Epoch 3/20\n",
      "3036/3036 [==============================] - ETA: 0s - loss: 1.8259 - accuracy: 0.4262WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "3036/3036 [==============================] - 585s 193ms/step - loss: 1.8259 - accuracy: 0.4262\n",
      "Epoch 4/20\n",
      "3036/3036 [==============================] - ETA: 0s - loss: 1.6585 - accuracy: 0.4802WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "3036/3036 [==============================] - 2705s 891ms/step - loss: 1.6585 - accuracy: 0.4802\n",
      "Epoch 5/20\n",
      "3036/3036 [==============================] - ETA: 0s - loss: 1.4952 - accuracy: 0.5283WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "3036/3036 [==============================] - 592s 195ms/step - loss: 1.4952 - accuracy: 0.5283\n",
      "Epoch 6/20\n",
      "3036/3036 [==============================] - ETA: 0s - loss: 1.3013 - accuracy: 0.5947WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "3036/3036 [==============================] - 592s 195ms/step - loss: 1.3013 - accuracy: 0.5947\n",
      "Epoch 7/20\n",
      "3036/3036 [==============================] - ETA: 0s - loss: 1.1043 - accuracy: 0.6621WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "3036/3036 [==============================] - 592s 195ms/step - loss: 1.1043 - accuracy: 0.6621\n",
      "Epoch 8/20\n",
      "3036/3036 [==============================] - ETA: 0s - loss: 0.9315 - accuracy: 0.7156WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "3036/3036 [==============================] - 591s 195ms/step - loss: 0.9315 - accuracy: 0.7156\n",
      "Epoch 9/20\n",
      "3036/3036 [==============================] - ETA: 0s - loss: 0.7436 - accuracy: 0.7777WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "3036/3036 [==============================] - 590s 194ms/step - loss: 0.7436 - accuracy: 0.7777\n",
      "Epoch 10/20\n",
      "3036/3036 [==============================] - ETA: 0s - loss: 0.5643 - accuracy: 0.8409WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "3036/3036 [==============================] - 591s 195ms/step - loss: 0.5643 - accuracy: 0.8409\n",
      "Epoch 11/20\n",
      "3036/3036 [==============================] - ETA: 0s - loss: 0.4374 - accuracy: 0.8796WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "3036/3036 [==============================] - 590s 194ms/step - loss: 0.4374 - accuracy: 0.8796\n",
      "Epoch 12/20\n",
      "3036/3036 [==============================] - ETA: 0s - loss: 0.3118 - accuracy: 0.9239WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "3036/3036 [==============================] - 590s 194ms/step - loss: 0.3118 - accuracy: 0.9239\n",
      "Epoch 13/20\n",
      "3036/3036 [==============================] - ETA: 0s - loss: 0.2278 - accuracy: 0.9493WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "3036/3036 [==============================] - 590s 194ms/step - loss: 0.2278 - accuracy: 0.9493\n",
      "Epoch 14/20\n",
      "3036/3036 [==============================] - ETA: 0s - loss: 0.1702 - accuracy: 0.9606WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "3036/3036 [==============================] - 590s 194ms/step - loss: 0.1702 - accuracy: 0.9606\n",
      "Epoch 15/20\n",
      "3036/3036 [==============================] - ETA: 0s - loss: 0.1137 - accuracy: 0.9799WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "3036/3036 [==============================] - 590s 194ms/step - loss: 0.1137 - accuracy: 0.9799\n",
      "Epoch 16/20\n",
      "3036/3036 [==============================] - ETA: 0s - loss: 0.0883 - accuracy: 0.9852WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "3036/3036 [==============================] - 590s 194ms/step - loss: 0.0883 - accuracy: 0.9852\n",
      "Epoch 17/20\n",
      "3036/3036 [==============================] - ETA: 0s - loss: 0.0693 - accuracy: 0.9883WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "3036/3036 [==============================] - 590s 194ms/step - loss: 0.0693 - accuracy: 0.9883\n",
      "Epoch 18/20\n",
      "3036/3036 [==============================] - ETA: 0s - loss: 0.0594 - accuracy: 0.9881WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "3036/3036 [==============================] - 590s 194ms/step - loss: 0.0594 - accuracy: 0.9881\n",
      "Epoch 19/20\n",
      "3036/3036 [==============================] - ETA: 0s - loss: 0.0534 - accuracy: 0.9890WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "3036/3036 [==============================] - 590s 194ms/step - loss: 0.0534 - accuracy: 0.9890\n",
      "Epoch 20/20\n",
      "3036/3036 [==============================] - ETA: 0s - loss: 0.0374 - accuracy: 0.9932WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "3036/3036 [==============================] - 592s 195ms/step - loss: 0.0374 - accuracy: 0.9932\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2b1e1d4cd60>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "np.array(trainInputs), one_hot_labels, verbose=1, epochs = 20, batch_size=2, callbacks = [tf.keras.callbacks.EarlyStopping(patience = 5)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e097aefb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "95aa9085",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('bertPersonality.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d34ea619",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as embeddings_layer_call_fn, embeddings_layer_call_and_return_conditional_losses, encoder_layer_call_fn, encoder_layer_call_and_return_conditional_losses, pooler_layer_call_fn while saving (showing 5 of 828). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://0cfa1ea6-5b9e-4ca4-9918-71bf05e4e8f8/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://0cfa1ea6-5b9e-4ca4-9918-71bf05e4e8f8/assets\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "s = pickle.dumps(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "19918a57",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as embeddings_layer_call_fn, embeddings_layer_call_and_return_conditional_losses, encoder_layer_call_fn, encoder_layer_call_and_return_conditional_losses, pooler_layer_call_fn while saving (showing 5 of 828). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://a1def7de-a2b4-4885-8c1a-d34f7f80ef19/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://a1def7de-a2b4-4885-8c1a-d34f7f80ef19/assets\n"
     ]
    }
   ],
   "source": [
    "pickle.dump(model, open('bertPersonality.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1ca8d3e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>posts</th>\n",
       "      <th>type_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4587</th>\n",
       "      <td>ISFP</td>\n",
       "      <td>dear isfj mother  i wish you were less of a w...</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2786</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>to me  i think you guys may be over analyzing...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2813</th>\n",
       "      <td>ENFP</td>\n",
       "      <td>nihm while nihm has her intj husband  i ve go...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3705</th>\n",
       "      <td>INTP</td>\n",
       "      <td>i want 5 kids    an astro nuclear theoretical...</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5957</th>\n",
       "      <td>ISFP</td>\n",
       "      <td>i have the same thing as well  i ve noticed t...</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2346</th>\n",
       "      <td>INTP</td>\n",
       "      <td>yikes    when i wall posted you i hadn t read...</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1814</th>\n",
       "      <td>ISFJ</td>\n",
       "      <td>i like eggs    i m sure there is at least prim...</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7695</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>i totally understand  i m also strange and th...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3769</th>\n",
       "      <td>INTP</td>\n",
       "      <td>do you have money to have someone else do the...</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6614</th>\n",
       "      <td>INFP</td>\n",
       "      <td>i ll be your friend       my mantra is not su...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2603 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      type                                              posts  type_index\n",
       "4587  ISFP   dear isfj mother  i wish you were less of a w...          13\n",
       "2786  INFJ   to me  i think you guys may be over analyzing...           8\n",
       "2813  ENFP   nihm while nihm has her intj husband  i ve go...           1\n",
       "3705  INTP   i want 5 kids    an astro nuclear theoretical...          11\n",
       "5957  ISFP   i have the same thing as well  i ve noticed t...          13\n",
       "...    ...                                                ...         ...\n",
       "2346  INTP   yikes    when i wall posted you i hadn t read...          11\n",
       "1814  ISFJ  i like eggs    i m sure there is at least prim...          12\n",
       "7695  INFJ   i totally understand  i m also strange and th...           8\n",
       "3769  INTP   do you have money to have someone else do the...          11\n",
       "6614  INFP   i ll be your friend       my mantra is not su...           9\n",
       "\n",
       "[2603 rows x 3 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testData['type_index'] = data['type'].apply(get_type_index)\n",
    "testData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f0797f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "testLabels = tf.keras.utils.to_categorical(testData.type_index.values, num_classes=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ece37dea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 101, 1050, 2615, ..., 2065, 2023,  102],\n",
       "       [ 101, 2092, 3374, ..., 1045, 2179,  102],\n",
       "       [ 101, 8840, 2140, ..., 4299, 1045,  102],\n",
       "       ...,\n",
       "       [ 101, 2821, 4372, ..., 1037, 8549,  102],\n",
       "       [ 101, 7632, 4372, ..., 2017, 3305,  102],\n",
       "       [ 101, 5875, 2017, ..., 4840, 2250,  102]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainInputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1087fa43",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cff8582a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 1., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testLabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "54a33273",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Data cardinality is ambiguous:\n  x sizes: 6072\n  y sizes: 2603\nMake sure all arrays contain the same number of samples.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [28]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtestInputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtestLabels\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\data_adapter.py:1851\u001b[0m, in \u001b[0;36m_check_data_cardinality\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m   1844\u001b[0m     msg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m sizes: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m   1845\u001b[0m         label,\n\u001b[0;32m   1846\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\n\u001b[0;32m   1847\u001b[0m             \u001b[38;5;28mstr\u001b[39m(i\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mnest\u001b[38;5;241m.\u001b[39mflatten(single_data)\n\u001b[0;32m   1848\u001b[0m         ),\n\u001b[0;32m   1849\u001b[0m     )\n\u001b[0;32m   1850\u001b[0m msg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMake sure all arrays contain the same number of samples.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1851\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n",
      "\u001b[1;31mValueError\u001b[0m: Data cardinality is ambiguous:\n  x sizes: 6072\n  y sizes: 2603\nMake sure all arrays contain the same number of samples."
     ]
    }
   ],
   "source": [
    "model.evaluate(np.array(testInputs), np.array(testLabels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8317b422",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54f0955c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
